
---

**摘要 (Abstract)**

神经形态微型机器学习 (vTinyML) 旨在解决边缘端的机器感知和智能问题，这些问题需要低延迟处理，并使用具有神经形态**事件驱动（event-based）**传感器接口和神经形态加速器的低资源处理器。本文报告了一种神经形态 TinyML 架构 (**vMCU**)，该架构可用于部署和处理边缘端事件驱动传感器的数据。

系统的核心是 SiFive 的 **RISC-V CPU**，用于算法开发。该 CPU 连接了一组通信和计算外设，其中最值得注意的是一个包含 **256Kib FIFO** 的事件驱动物理接口、一个可编程的 **47位时间戳单元**，以及一个采用基于电荷处理和**伪 DRAM (pseudo-DRAM)** 单元基元的嵌入式**存内计算 (CiM)** 关联处理器。

vMCU SoC 采用 **65nm CMOS** 工艺制造，芯片尺寸为 7mm x 4mm，运行频率为 **100MHz**，其物理接口的最大事件吞吐量为 **17 Meps** (百万事件每秒)。利用 CiM 加速器能力对长位向量进行的二进制和整数运算仅消耗数 fJ (飞焦) 每操作。vMCU 的功耗为 **30mW**，并在多种嵌入式应用任务中进行了演示，包括基于 DAVIS240C 事件相机的字符识别。

**关键词**——边缘计算，SoC，存内计算 (compute-in-memory)，神经形态，tinyML

---

**I. 引言 (INTRODUCTION)**

人机交互、机器人和虚拟现实等应用对现代最先进的嵌入式设备提出了挑战。解决这些问题的方案可以借鉴大脑的处理方式，即在感觉源头附近部署基于事件的通信和计算。神经形态 TinyML 致力于实现微架构，通过以低延迟、高能效的方式利用**稀疏的 (sparse)**、基于事件的感知信息来执行机器学习和计算机视觉任务。

用于架构和算法探索的神经形态嵌入式平台已部署在 FPGA 和其他基于微控制器的平台上 [1], [2]。然而，目前尚未有关于具有嵌入式计算和通信单元的**专用神经形态微控制器架构**的报道。在本文中，我们报告了一种 RISC-V 神经形态微控制器单元 (vMCU) 的架构、流片制造、测试和应用开发，该 MCU 具有专为采用事件驱动传感器（视觉 [3]、听觉 [4]、触觉 [5] 等）的低延迟嵌入式应用而设计的物理接口和微架构单元。

第 II 节概述了 vMCU 架构和 RISC-V CPU 核心。第 III 节概述了事件驱动传感器接口和存内计算 (CiM) 加速器的操作。最后，在第 IV 节演示 vMCU 的操作并列出初步规格，随后在第 V 节得出结论。

---

**II. vMCU 架构 (VMCU ARCHITECTURE)**

![[Pasted image 20260130172125.png]]

嵌入式 SoC ASIC 的整体框图如图 1 所示。该微架构由一系列计算和通信控制器及外设组成，所有这些模块都通过 **64位 高级微控制器总线架构 (AMBA) [6] 高级高性能总线 (AHB) 矩阵**进行交互。

系统的核心是 **SiFive S7 系列核心 (RV64IMAFDS)**，它具有单精度和双精度浮点单元、**32KiB 指令缓存和数据缓存**、64位 AHB 系统/存储端口、标准 UART 和 SPI 接口，以及四个 **2Mib SRAM 库（总计 1MiB）**。

外部通信通过一对 UART 和 SPI 接口建立，用于加载 S7 程序并实现串行数据传输。系统存储器由一个 1 MiB 的 SRAM 模块组成，用于容纳指令空间和参数数据。

为了在边缘端实现高效的神经形态感知，系统引入了两个额外的外设：

1.  第一个是**神经形态传感器外设 (NSP)**，它从片外事件驱动相机接收地址事件 (AEs)，类似于文献 [3]。该模块负责解码事件，并通过**中断信号 (interrupt signaling)** 与 CPU 通信，以便 CPU 读取和处理数据。
2.  最后，设计并植入了一个**四核 CiM 加速器**，旨在以高能效的方式计算大多数机器学习和计算机视觉应用所需的定点算术运算。

**对于这篇论文的“槽点”与你的机会：**

- **配置过剩 (Overkill)**：对于一个 **TinyML (微型机器学习)** 芯片，尤其是做 SNN（脉冲神经网络）这种通常只需要 1-bit 或 8-bit 精度的应用，**配备一个 64-bit 的双精度浮点单元是非常浪费的**。
    
- **面积与功耗**：双精度 FPU 面积很大，且运算极其费电。
    
- **架构矛盾**：
    
    - **CiM 加速器**：做 1-bit/8-bit 低精度运算（极低功耗）。
        
    - **RISC-V CPU**：却挂了一个昂贵的 FP64 单元。
        
    - **你的创新点**：你的数字系统可以强调 **“移除不必要的 FPU，改用针对 SNN 优化的专用算术单元”**，这将是巨大的能效提升点。
---
### A. SiFive CPU（中央处理器部分）

SiFive S7 系列 RISC-V CPU [7] 是 SoC 中嵌入式算法和各外设的核心控制器。如图 2 所示，其配置包括一个 **64 位双精度浮点核心**、**32KiB 的 4 路组相联（4-way）指令缓存和数据缓存**，以及 32 个全局中断。这些中断具有 7 个优先级，由**平台级中断控制器 (PLIC)** 统一处理。此外，还可选配**核心本地中断器 (CLINT)**。

存储器（SRAM）连接在 **64 位 AHB 存储端口 (Memory Port)** 上，以便能够利用缓存（Cache）加速访问；而包括 CiM 加速器和神经形态传感器外设 (NSP) 在内的其他外设，则连接在 **系统端口 (System Port)** 上。

通过预编程的引导加载程序（Bootloader）以及 UART 或 SPI 外设，可以将编译好的软件加载到 **1 MiB 的 SRAM** 中。系统开发使用预构建的 RISC-V GCC 工具链，并辅以针对专用接口和处理单元定制的**应用编程接口 (API)**。这些定制 API 屏蔽了底层操作细节，开发者只需通过读写特定的**内存映射地址 (Memory-mapped addresses)**，即可完成设置配置参数、启动外设功能以及读取计算结果等任务。

---

### III. 神经形态通信与计算外设

SoC 中增加了计算和通信外设，以实现可编程性、传感器连接以及高能效的**定点算术运算 (Fixed-point arithmetic)**。

UART 和 SPI 外设用于芯片内外的数据迁移（搬运），包括在 CPU 启动（Boot）期间。系统通过 **3 个外部引脚**来配置引导加载程序（Bootloader），使其能从任一外设读取初始程序配置，同时选择系统存储器（SRAM）中的目标存放位置。最终，这些接口还可以配置为与现有的各种 UART 或 SPI 无线模块配合工作，从而使该 SoC 具备物联网 (IoT) 应用能力。


### 第一部分：内容翻译（IV. 实验结果）

**vMCU 架构设计、验证并采用低功耗 65nm CMOS 工艺实现。** 图 6 展示了带有模块标注的设计顶层版图。该 ASIC（专用集成电路）的大部分面积被 **1MiB 的系统存储器**占据。四核 CiM 加速器包含 **32KiB 的伪 DRAM**，既可作为额外存储使用，也可用于第 III-A 节所述的高能效算术运算。神经形态传感器外设（NSP）使用了一个 **4096x64 (32KiB) 的 FIFO** 进行内部事件缓冲。为了验证和表征该 SoC，使用了 Opal Kelly XEM7310 FPGA 开发板和 Python API 来配置板载 DAC（数模转换器），以为芯片提供电源和偏置，并通过 UART 和 SPI 接口向芯片发送串行数据。测试装置见图 7。

作为初步测试并展示其嵌入式处理潜力，作者在 **S7 CPU** 上部署了一个量化版的 **LeNet 神经网络**，对 N-MNIST 数字进行边缘推理。在运行期间，测量得 SoC 的**功耗为 30mW**，比部署在 FPGA 上的同类架构功耗低 30 倍。N-MNIST 数据集的数据是通过在 MNIST 样本前快速移动（扫视）DAVIS240C 相机生成的。测试样本的图像数据使用 AER 发射机模型传输至 vMCU。

每个样本通过中值阈值化处理产生二值化表示，有效的像素地址经过**一阶独热编码（one-hot encoded）**后传输至 SoC，由 NSP 接收。当输出 FIFO 中累积了一定数量的事件后，**S7 CPU 会从外设中读取数据**并在内部数组中填充解码后的图像数据。读取完成后，S7 处理器使用接收到的图像进行神经网络前向计算，并将分类结果通过 UART 串口传输至 PC。

图 8 展示了在训练后的模型上验证测试集得到的混淆矩阵。使用该嵌入式模型实现了 **95% 的分类准确率**。

**目前仍需进一步工作来将 CiM 加速器完全整合到神经网络的乘累加（MAC）操作中。** 为了测试 CiM 加速器的计算效率，作者进行了独立表征。在 100MHz 系统时钟下测试了两种操作：**1-bit 乘累加**（类似于神经元激活函数）和 **完整的 8-bit 乘累加**。记录的吞吐量（包括数据传输开销）反映在表 I 中。

---

### 第二部分：图 8 讲解（N-MNIST 旋转模型混淆矩阵）

这张图是衡量机器学习模型分类性能的经典工具。对于你的 SoC 设计研究，这张图证明了**数字系统数据流（从传感器接口到 CPU 处理）的完整性**。

#### 1. 坐标轴含义
*   **纵轴 (True label)**：样本真实的数字（0 到 9）。
*   **横轴 (Predicted label)**：SoC 预测出来的数字（0 到 9）。

#### 2. 如何读图
*   **对角线（从左上到右下，颜色偏亮的部分）**：代表预测正确的数量。例如，左上角的 **8634** 表示有 8634 个数字“0”被正确识别为了“0”。
*   **非对角线区域（颜色偏暗的部分）**：代表预测错误的数量。例如，在纵轴为 9、横轴为 4 的位置（数字 225），表示有 225 个数字“9”被错误地识别成了“4”。
*   **颜色深浅**：右侧的色柱代表数值。越趋向黄色，代表该方格内的样本数越多；颜色越深（趋向紫色），代表样本数越少。

#### 3. 这张图背后的技术意义
*   **95% 的准确率**：说明这个 65nm 的 SoC 成功跑通了整个数据通路。
*   **数据有效性**：虽然 CiM 还没完全参与运算（这篇论文的 LeNet 是在 CPU 上跑的），但这张图证明了 **NSP 模块（传感器接口）** 解码事件、打时间戳、存入 FIFO 并被 CPU 读取的过程是完全正确的，没有发生数据丢失或损坏。

---


1.  **CPU 的沉重负担（瓶颈）**：
    原文提到：“S7 reads from the peripheral and populates an internal array”。这意味着 **CPU 充当了“搬运工”的角色**。在 17Meps 的高吞吐量下，CPU 频繁被中断并去读 FIFO 填充数组，这会极大地拖慢推理速度。
    *   **你的改进点**：设计一个专用 **DMA** 自动把 NSP 的数据搬到主存 SRAM，让 CPU 只负责启动计算。

2.  **CiM 尚未“合体”**：
    文中承认 CiM 加速器目前是**独立测试**的，并没有真正参与 LeNet 的前向推理。这说明该 SoC 的**控制路径（Control Path）**还不够完善，导致 CPU 无法高效地调用 CiM 核。
    *   **你的改进点**：在你的 $64 \times 16$ 阵列设计中，要重点设计**指令调度逻辑**，让 CPU 能像调用一个库函数一样简单地使用加速器，而不是像这篇论文一样只能单独表征。

3.  **功耗占比预估**：
    整个 SoC 功耗 30mW，而 CiM 内部运算其实是飞焦（fJ）级别的，非常省电。这说明 **30mW 里的绝大部分功耗都消耗在了 RISC-V CPU 不断地搬运数据和运行软件代码上。**
    *   **结论**：优化数字系统的数据搬运逻辑（减小 CPU 参与度），是降低系统级功耗的关键。

# ✅ 为什么“事件驱动论文”仍值得参考

你要的不是它的事件机制，而是**它暴露的 SoC 瓶颈**：

1. **CPU 变成搬运工**
    
    - 这是“系统级错误设计”的典型案例
    - 你可以拿来作为**对比和反例**
2. **CiM 没有真正接入推理流程**
    
    - 反映出**控制路径/调度不完善**
    - 这是你可以强调的创新方向：  
        “让 CPU 像调用库函数一样用加速器”
3. **系统功耗远高于算子功耗**
    
    - 说明 SoC 功耗主要消耗在“搬运 + 软件控制”
    - 这是你做 DMA/缓冲/减少 CPU 参与的核心动机

这些问题在**事件驱动 or 同步系统**里都存在，**具有共性价值**。

---

# ✅ 你可以这样用这篇论文

**在论文里引用它作为“痛点证据”**：

- “虽然 CiM 核本身能效极高，但系统级功耗仍被 CPU 控制和数据搬运主导”
- “CPU 在高吞吐场景频繁处理中断，导致系统性能下降”

然后引出你的创新点：

- DMA 自动搬运
- 低 CPU 参与
- 简化加速器调用路径

## 今日开会的纪要

原顺序：

1、做好ppt内部确认，
2、和zys，
3、再和cq，
4、然后cq和zys，
5、最后（with zl汇报）三人组会

现顺序：

1、直接遇见了zys
2、直接开聊，约定开会
3、开完了（我 cw zys 还有张国滨，还有两个他们组研一的新生），技术汇报完了，达成了合作意向，我让zys打给了cq，cq表示同意

  -----zys和cq达成了共识，确认了方案：cw暂时赋能zys，26再招一个学生赋能yb的器件，cw和26新学生都用一样的接口，数字电路全都可以支持，给yb交差（暂定，具体搞成啥样idk），zys表示他那边早就说服yb了，问题不大，到时候我去汇报，cq和zys补充（没提zl）


开会确定的具体技术信息：

1、器件信息
器件那边，python的 spice的 Verilog-a的模型应有尽有，预计今晚拿到手，我直接开始拿python建模仿真去---预计本周末完成

器件信息： 写2v 读1v 0T1R

2、方案确认

要做读、写、写验证、擦除

3、权重编码的形式---解决正负的问题

采用差分结构，阵列决定做128x128，由于是差分，因此实际上是128x256（他们想做的大一些）

但是识别实际上是需要49x10，本来就pad不够，几十根线，要爆炸了，然后变成128x256那就更夸张了，因此：

需要行列选通，数字一侧先发信号，做行和列的选通，读取特定的49x20（差分）

然后就发现了问题，49是一个很恶心的数，不方便去批量选取

因此采取，先28x28，然后padding，变成32x32，然后再进行压缩，变成8x8

然后这样变成了128----8x8

想着搞4个4-16译码器，每个译码器选中16行，4个译码器一共选中8x8共计64行

然后列也是，选中20列（因为是差分），具体方案我还没想好

4、zys提出的小小创新点：

做阈值adapted----如果发放的很频繁，那就阈值变大，如果发放的不频繁，那就阈值变小，自适应，模仿生物

## 昨日改动：

## 1) 建模---确定算法准确率与一部分参数

1) 软件预处理：MNIST 28×28 → 7×7（选择最合适降采样方式）  

2) 训练/量化：训练得到 W，再映射到器件可用的 conductance levels  

3) 加入器件噪声/漂移模型 + ADC 量化模型
  
4) 扫描参数并输出曲线：
   - ADC bits（8/10/12/14…） vs 准确率  
   - 量化位宽（权重 bit） vs 准确率  
   - 噪声强度 vs 准确率  

3) 然后进行参数决策：

   - ADC 位数（满足算法精度的最低位数 + 裕量）  
   - 阈值/膜电位位宽（保证不溢出且利于稳定发放）  
   - 是否需要 Program-and-Verify / Reference Column / 校准周期  
   - DMA/Buffer 是否要扩展（例如写权重/搬运结果/减少 CPU 参与）

---

## 2) CPU存在的意义&&数据流和控制流的分离

- **数据流/控制流分离原则**补充进总览&工程文档：  
  - 数据流：`data_sram → DMA → input_fifo → CIM → output_fifo`  
  - 控制流：CPU 仅做配置/启动/读结果

我个人思索了一下MCU VS CPU，我觉得主要是有以下几点：

(1)可编程性
FSM 固定死流程，任何改动都要改 RTL。

通过ALU，实现 地址计算、寄存器配置、循环控制、DMA 启动、数据搬运。没有 ALU 就不是 CPU 了，只能退化成固定 FSM，灵活性没了

CPU 可以只改固件，从而

改阈值
改 timesteps
改输入格式
改推理流程

同一硬件，换阈值/帧数/编码方式即可跑不同实验

(2) 外部接口桥梁
要接 UART/SPI/Flash，必须有一个软件层能解析数据并写寄存器。
没有 CPU，就得靠 FPGA 或外部 MCU 控制，工程复杂度更高(maybe?)。

(3) 为 V2/V3 打基础
后面预想的创新点很多需要 CPU 配合
V1 集成 CPU = 给后续版本留接口

我个人觉得，主要是在于，用一个cpu，可以实现可编程性、外部接口、复现能力，以及 V2/V3 创新点的基础（当然，也有想借着这个机会好好了解一下cpu的私心）

---
## 3) DMA&FIFO存在的意义？

我感觉暂时可以称之为最小化单通道 DMA，确实不算通用 DMA（昨天复习了一下）。

为什么仍叫 DMA（我个人理解）：

Direct：CPU 只配置寄存器，不参与逐字节搬运
Memory：源端是 data_sram
Access：DMA 有独立读口，自动搬运到 input_fifo

后续（等3月）我打算扩展 DMA 支持 SPI → SRAM，那么会变成：

Flash → SPI → DMA → data_sram → DMA → input_fifo

这样 CPU 参与更少，更符合DMA的概念（个人理解，不一定对，如果有问题我再改）。

昨天去试着合并了一下FIFO和DMA，发现：

DMA 搬运是突发；CIM/ADC 是时序驱动、间歇的；FIFO 吸收速度不匹配。

没有 FIFO 就必须严格同步 DMA 与 CIM，验证复杂度大幅上升。

因此，DMA 和 CIM/ADC 的速度不同，如果有FIFO的存在，FIFO 可以说是缓冲器。  

合并后变成“边读边算”，一旦 ADC/CIM 慢下来就卡住，验证更难（时序耦合更强）。

---

## 4) 面积压缩：之前没注意，算了算如果不改，直接爆了

### 4.1 SRAM 尺寸统一压缩
- 指令 SRAM：16KB  
- 数据 SRAM：16KB  
- 权重 SRAM：16KB（暂保留）
> 全部通过 `snn_soc_pkg.sv` 参数集中管理，避免硬编码。

### 4.2 FIFO 深度调整
- **INPUT_FIFO_DEPTH=256**  
  - 本来想压缩面积来着，结果发现原压缩到 128 后发现 TB 会死锁（TIMESTEPS×PIXEL_BITS=160 > 128）。  
- **OUTPUT_FIFO_DEPTH=256** 保持不变。

---

## 5) 迭代路线与创新点补充
- **V1/V2/V3 路线明确**  
  - V1：数字单独流片 + 片外混合集成  
  - V2：Program-and-Verify / 校准等强依赖器件特性的机制  
  - V3：片上数模混合集成
  - 
- **根据建议，新增创新点**：数锁相（数字 PLL/DPLL）作为 V2/V3 备选（了解了一下，感觉非常promising）

---





# 器件组合作对齐会议材料（Demo）

**用途**：用于与“器件/材料课题组”第一次系统级对齐（老师 + 学生均可读）。  
**目标**：让双方对“我们要做什么、怎么做、当前做到哪、下一步需要什么信息”形成同一张地图。  
**版本**：v0.2（可按会后结论迭代）
**日期**：2026-02-05
**参数口径**：本项目所有默认参数/位宽/地址范围以 `rtl/top/snn_soc_pkg.sv` 为准；文档若有不一致，以 pkg 为准。

> **v0.2 变更备忘（相对 v0.1）**
> - 修正 §5.2：DMA 流程描述（DMA 先填满所有 bit-plane，再启动 CIM 循环；原文为逐帧穿插描述，与实际 TB 行为不符）
> - 补充 §8：关于器件组可能提供 SPICE 模型的处理建议
> - 补充 附A：片外引脚数估算（~73 pin）
> - 补充 附B：时钟频率
> - 移动 §3'（Memory Macro 支线）→ 附C（首次会议建议先聚焦主线）

---

## 0. 一句话说明：我们要做什么

我们要做一个 **SNN SoC（脉冲神经网络系统芯片）**，其中 **模拟 CIM Macro（二维材料 RRAM 阵列 + DAC/ADC）** 作为 SoC 里的一个加速 IP。  
数字 SoC 负责 **数据搬运、时序控制、量化接口、神经元累加与阈值发放（spike）**，并与模拟宏进行片外/片上系统级协同验证。

---

## 1. 为什么这是“系统级工作”（给材料同学的直观解释）

器件/材料通常关注：“单个器件/小阵列能不能稳定写读、能做到多少级电导、噪声/漂移多大”。  
系统级 SoC 关注：“把它放进一个完整系统后，**数据怎么进来、怎么算、算完怎么出去、整机能耗/吞吐/准确率如何**，以及为了适配器件的不完美，数字侧需要做哪些机制”。

换句话说：  
**器件给我们‘可用的物理算子’，我们负责把它变成‘可复现、可评估、可写论文’的端到端系统。**

---

## 2. 三方分工与边界（器件/模拟/数字）

### 2.1 器件/材料侧（你们）
- 二维材料 RRAM 单元与阵列实现、后道工艺集成（BEOL/后道集成路线）
- 提供 **可量化的数据**：电导范围/级数/分布、噪声、漂移、写读条件等

### 2.2 模拟电路侧（我们团队的模拟同学/你们也可能参与）
- DAC/ADC、MUX、偏置/参考、读写脉冲整形等外围电路
- 给出 **接口电气/时序约束**（例如：读出建立时间、ADC 采样时间、输出范围等）

### 2.3 数字 SoC 侧（我负责）
- SoC 控制与数据通路：DMA / FIFO / 控制器 / LIF 神经元 / 寄存器映射 /（V1 完整版含 CPU 外设）
- 与模拟宏的数字接口协议定义与实现（握手、通道选择、数据采样时序）
- Python 端到端建模（含量化/噪声）→ 反推 ADC 位数、阈值、数据搬运策略等设计决策

---

## 3. V1 → V2 → V3 迭代计划（流片与集成方案 + 创新点）

### V1（2026/06/30）：数字 SoC 单独流片（风险最低，先保证“系统跑通”）
- **流片形态**：数字 SoC 单独流片
- **验证方式**：用仿真行为模型替代模拟宏；后续与模拟宏进行片外连接验证
- **数字侧目标**：
  - 时序正确、功能跑通、回归/烟测/静态检查（lint）稳定
  - 完整数据链路跑通：`data_sram → DMA → input_fifo → DAC/CIM/ADC 控制 → LIF → output_fifo`
  -（V1 完整版规划）E203 + UART/SPI/AXI-Lite 形成“可运行固件”的系统骨架
- **适合放在 V1 的低风险创新点（可选，按时间评估）**：
  - 固定路径 DMA + FIFO 速率解耦（已在 MVP 中体现）
  - 结果集中读取（Shadow Buffer，用于 ADC 时分复用后的结果集中读取）
  - 稀疏性统计/活动检测（全 0 bit-plane 跳过，节能且好解释）
  - 层级使能门控（同步 enable/clock-enable，不做异步电路）

### 并行进行（与 V1 同时）：模拟宏/器件阵列单独流片 + 后道集成 RRAM
- **流片形态**：模拟宏测试芯片（含阵列/读写/ADC/DAC 等）单独流片
- **目标**：把“器件可用性”从系统里拆出来先跑通：写读一致性、噪声、漂移、可靠性、接口时序等

### 数字与模拟分别验证成功后：片外数模混合集成（系统级对齐）
- 两颗芯片分别上板（各自 PCB），通过排针/连接器做片外互联
- 在同一时钟/复位下跑通端到端推理流程
- 这一步的价值：用最可控的方式，把“器件/模拟不确定性”导入系统评估闭环

### V2：数字侧加入“强依赖器件特性”的机制（在器件数据稳定后再做）
- **Program-and-Verify FSM（自动写-读-验）**：把反复编程/验证从 CPU 卸载到硬件状态机
- **Reference Column + 动态校准**：对漂移/温漂做系统级补偿（需要物理结构支持）
- **更完整的搬运路径**：例如 SPI→DMA→SRAM、或 ADC 结果 Shadow Buffer + 中断/一次性搬运
- （可选）**数锁相（数字 PLL/DPLL）**：用于多时钟域/动态调频（有明确需求时再做）

### V3：片上数模混合集成（最高风险、最高系统完整度）
- 数字 SoC 与模拟 CIM Macro 在同一颗芯片（或同一封装/同一 die）实现片上互联
- 引入电源域/噪声隔离/时钟策略等更复杂的 SoC 级约束

---

## 3'. 支线合作方向（未来）：Memory Macro

> 此部分已移至 **附录 C**；首次对齐会议建议先聚焦 SNN SoC 主线。

---

## 4. V1（数字 SoC）架构是什么（老师可快速扫）

### 4.1 顶层模块（概念框图）

```
外部输入（V1 完整版）
  Flash --SPI--> CPU(E203) --写--> data_sram
                     |  配寄存器/启动/读结果
                     v
                 DMA 引擎  ---> input_fifo ---> DAC/CIM/ADC 控制链 ---> LIF ---> output_fifo
                                                       |
                                                       v
                                                 bl_data[ADC_BITS-1:0]

外部输出（V1 完整版）
  CPU(E203) --UART--> PC（打印日志/传输结果）
```

### 4.2 数据流 vs 控制流（强烈建议对齐的工程原则）
- **数据流（固定通道）**：`data_sram → DMA → input_fifo → CIM → output_fifo`
- **控制流（可编程）**：CPU 仅做 **配置/启动/读取结果**；核心推理不靠 CPU “一拍一拍”参与

> 这样做的好处：系统可扩展、验证难度低、论文里也更容易讲清楚“系统瓶颈在搬运而不是算子”。

---

## 5. 一次推理是怎么跑的（从上电到输出）

### 5.1 输入编码（当前 MVP 的假设）
- MNIST 28×28 灰度图（8-bit）→ 软件降采样为 7×7（49 像素）
- 每个像素 8-bit → **bit-plane**：把一张图拆成 8 个子时间步（MSB→LSB）
- 同一子时间步内：并行送入 49 个像素的第 x 位（49 路 0/1）

### 5.2 关键循环（每帧 8 个子时间步）

**前置步骤**：DMA 一次性将当前帧全部 8 个 bit-plane（每个 49-bit，共 8 条）填入 input_fifo，然后置位 `dma_done`。DMA 填充与 CIM 推理流水**不交叉**（TB 流程：DMA START → 轮询 DONE → 再 CIM START）。

input_fifo 就绪后，对每一帧（TIMESTEPS 次，可重复同一张图以积累膜电位），控制器按 MSB→LSB 顺序逐个 bit-plane 执行：
1. 控制器从 input_fifo 取出一个 bit-plane → DAC 握手锁存 `wl_spike[48:0]`
2. 触发 CIM 计算 `cim_start`，等待 `cim_done`
3. ADC 时分复用 10 路输出：`bl_sel=0..9`，每路 `adc_start/adc_done` 一次，采到 `bl_data`
4. LIF 以 `bitplane_shift` 作为权重位：做 `shift-and-accumulate`，超过阈值则产生 spike 写入 output_fifo
5. 一帧 8 个 bit-plane 完成后进入下一帧；所有帧完成后 done

### 5.3 为什么会有 TIMESTEPS（帧数）
在真实 SNN/低电压低噪声设计里，很多情况下需要 **跨多个时间步积累** 才容易超过阈值形成稳定 spike。  
工程上 TIMESTEPS 是一个“系统级旋钮”：可用来做性能/能耗/准确率权衡，也方便实验复现。

---

## 6. 当前工程做到什么程度了（MVP 现状）

### 6.1 已实现（可仿真跑通 + 通过 lint）
- 总线/寄存器映射（simple bus）
- instr/data/weight SRAM（当前默认各 16KB）
- DMA（固定路径：data_sram → input_fifo）
- input_fifo / output_fifo（速率解耦与事件缓冲）
- SNN 控制链：DAC_CTRL / CIM_CTRL / ADC_CTRL（含 10 路时分复用）
- LIF 神经元：按 bitplane_shift 移位累加 + 阈值比较 + spike 输出
- CIM Macro：仿真用行为模型（可复现输出），综合时为黑盒（替换真实宏）
- TB/脚本：VCS+Verdi smoke test、Verilator lint

### 6.2 未实现/占位（V1 完整版要补）
- UART/SPI/JTAG：目前是 stub（占位，不做真实协议）
- CPU(E203) + AXI-Lite 总线：规划中，后续接入以支持固件/外部 Flash 启动

---

## 7. Meeting 需要拿回来的器件信息（优先级排序）

> 目的不是“收集一堆参数”，而是为了支撑 **量化映射/接口方案/ADC 位数/可靠性策略** 的关键决策。

| 优先级 | 需要确认的信息                                         | 用于（数字/系统侧决策）                                 |
| --- | ----------------------------------------------- | -------------------------------------------- |
| 🔴  | **电导值范围与级数**（conductance range + levels，含分布/方差） | 权重量化映射、输出动态范围、ADC 位数初值                       |
| 🔴  | **是否支持写权重** + 写入接口要求（脉冲类型/幅度/宽度/次数/是否需要 verify） | 决定是否做 Program-and-Verify、是否需要写入通路/寄存器/DMA 扩展 |
| 🟡  | **读噪声特性**（RMS/峰峰值、随温度/时间变化、与读电压关系）              | Python 建模中 ADC 误差/ENOB 估算、容错策略               |
| 🟡  | **阵列规模上限**（是否允许 49×10；更大阵列的 IR drop/串扰约束）       | 确认物理可行性，决定是否需要逻辑 64×16 / 分块处理                |
| 🟢  | **温漂、保持、耐写次数**（drift/retention/endurance）       | V2/V3 可靠性与校准策略（现在知道越早越好）                     |

### 建议额外补充（很关键，但材料同学容易忽略）
- **权重“正负号”怎么支持？**  
  训练得到的权重通常有正负；需要确认：差分阵列/双阵列相减/2T2R/offset mapping 哪一种可行。  
  这会直接影响 ADC 量化范围（单极/双极）与系统精度。
- **读出电压/电流范围**（ADC 前端输入范围 & 饱和点）  
  用于把“电导/电流”换算到“ADC code”的动态范围。
- **读出延迟/建立时间**（settling time）  
  用于定系统时序参数（DAC/CIM/ADC latency），决定控制器节拍与吞吐。

---

## 8. 希望器件组提供的“交付物”（建议格式）

为了让系统建模可复现，建议你们以“可直接被 Python 读取”的形式提供数据：

1) **电导级数据表**（建议 CSV/Excel）
- level index → 典型值（mean）→ 方差/分布（std 或直方图）
- 若有器件间/周期间差异，也建议分别给出

2) **读噪声模型**
- 噪声的量纲（电导/电流/电压/ADC code）与随条件变化关系

3) **写入条件与可编程性**
- 写脉冲（幅度/宽度/次数/极性/是否需要 forming）
- Program-and-Verify 是否必要、verify 的判据（误差容忍）

4) **阵列/单元结构信息**
- 是否差分（正负权重）  
- 阵列可行规模与主要限制因素（IR drop、串扰、sneak path 等）

> 有条件的话：给一个"可简化的行为级模型"（哪怕只是一套经验公式），系统端会非常好用。
>
> **关于 SPICE 模型**：如果器件组会提供 SPICE 仿真模型，它适用于电路级验证（模拟宏内部），但**不能直接代入系统级 Python 仿真**（层级不匹配）。系统端真正需要的是从 SPICE/测量中**提取**的宏观参数（见第 7 节优先级列表）。建议会上提前对齐这一点，避免交付物不对齐。

---

## 9. 我们拿到器件信息后会做什么（Python 建模 → 设计决策）

我们会建立一个与硬件链路一致的端到端仿真：

1) 软件预处理：MNIST 28×28 → 7×7（选择最合适降采样方式）  
2) 训练/量化：训练得到 W，再映射到器件可用的 conductance levels  
3) 加入器件噪声/漂移模型 + ADC 量化模型  
4) 扫描参数并输出曲线：
   - ADC bits（8/10/12/14…） vs 准确率  
   - 量化位宽（权重 bit） vs 准确率  
   - 噪声强度 vs 准确率  
5) 形成 V1/V2 的系统级设计决策：
   - **ADC 位数**（满足算法精度的最低位数 + 裕量）  
   - **阈值/膜电位位宽**（保证不溢出且利于稳定发放）  
   - 是否需要 Program-and-Verify / Reference Column / 校准周期  
   - DMA/Buffer 是否要扩展（例如写权重/搬运结果/减少 CPU 参与）

---

## 10. Meeting 建议议程（60-90 min）

1) 10 min：我们讲系统目标、V1/V2/V3 计划与接口边界  
2) 20 min：器件组讲阵列方案、现有测量数据、可编程性与限制  
3) 20 min：对齐“正负权重支持方式”与“ADC 动态范围/位数”  
4) 10 min：对齐片外互联可行性（引脚/电平/时钟/复位/握手时序）  
5) 10 min：确认交付物格式、时间表、下一次对齐节点

---

## 附 A：数字 ↔ 模拟接口信号摘要（当前版本）

完整定义见：`doc/08_cim_analog_interface.md`  

| 信号 | 方向 | 位宽 | 说明 |
|---|---|---:|---|
| clk / rst_n | D→A | 1/1 | 系统时钟/复位 |
| wl_spike | D→A | 49 | 49 路并行 1-bit（bit-plane） |
| dac_valid / dac_ready | D↔A | 1/1 | DAC 数据握手 |
| cim_start / cim_done | D↔A | 1/1 | CIM 计算启动/完成 |
| bl_sel | D→A | 4 | ADC 通道选择（0..9） |
| adc_start / adc_done | D↔A | 1/1 | ADC 采样启动/完成 |
| bl_data | A→D | 12 | ADC 输出（当前默认 12-bit） |

> **片外引脚数估算**：上表信号合计约 **73 pin**（clk×1 + rst_n×1 + wl_spike×49 + dac_valid/ready×2 + cim_start/done×2 + bl_sel×4 + adc_start/done×2 + bl_data×12）。对于片外混合集成方案，引脚数在合理范围内，可与封装/PCB 互联可行性一同评估。

---

## 附 B：当前关键参数（便于会中统一口径）

- 输入维度：`NUM_INPUTS = 49`（7×7）
- 输出类别：`NUM_OUTPUTS = 10`
- 像素位宽：`PIXEL_BITS = 8`（每帧 8 个子时间步，MSB→LSB）
- 默认 ADC 位数：`ADC_BITS = 12`
- 默认帧数：`TIMESTEPS_DEFAULT = 20`（可配）
- input_fifo 深度：`INPUT_FIFO_DEPTH = 256`
- output_fifo 深度：`OUTPUT_FIFO_DEPTH = 256`
- 膜电位位宽：`LIF_MEM_WIDTH = 32`
- SRAM：instr/data/weight 默认各 16KB（目前以面积约束为导向）
- 系统时钟：`50 MHz`（当前 TB/仿真默认值）

---

## 附 C：支线合作方向（未来）—— Memory Macro

> 此部分从 §3' 移入附录；首次会议建议先聚焦 SNN SoC 主线，后续再专题讨论。

### 背景与动机
- 器件组的氧化物 RRAM 在 **binary**（两态）情况下性能很好，且在面积上有机会做到 **同等容量 SRAM 的 ~1/10**（这一点仍需要以实际 PDK/版图与外围电路面积评估为准）。
- 团队希望把 RRAM 推向"存储器产品化/产业化"方向：对外表现为"像 SRAM 一样可用的存储器"，但内部存储介质换成 RRAM。

### 目标（一句话）
为 RRAM 阵列设计 **数字外围电路（digital periphery）**，把它封装成一个"可集成进 SoC 的存储器宏"，提供清晰、稳定、可验证的存储器接口与时序。

### 可能负责的部分（数字外围电路的典型内容）
- **地址译码/行列选择**：row/column decoder、片选、字线/位线控制时序
- **读写控制状态机**：
  - 写：写脉冲序列/脉宽/幅度控制（通常需要与模拟/器件侧接口配合）
  - 读：sense 触发、采样锁存、读延迟管理
- **数据通路封装**：读数据寄存/对齐、写数据缓冲
- **可靠性增强（按需求选配）**：
  - 简单 ECC / parity（如果 BER/漂移需要）
  - BIST（自测）、坏块/冗余行列（yield 友好）
  - wear leveling（若写入频繁且耐写受限）

### 预期交付形态（可选两种路线）
- 路线 A（更像"产品存储器"）：提供 SRAM-like 接口（addr/data/we/ce/ready 等），可被 SoC 当作片上 RAM 使用。
- 路线 B（更像"可编程器件"）：提供 memory-mapped 寄存器 + 命令队列（program/read/verify），更利于早期验证与参数可调。

### 什么时候聊/什么时候做
- **优先级**：低于 SNN SoC 主线；建议在 SNN SoC V1 稳定（仿真/文档/接口都收敛）后再启动。
- **启动条件**：器件侧能提供"可重复的阵列读写模型/测量数据"，并能明确读写时序与误码水平（至少给出一个可工作的试验窗口）。
